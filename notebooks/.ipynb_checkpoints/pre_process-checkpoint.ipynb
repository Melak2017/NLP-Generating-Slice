{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e7d6b3f",
   "metadata": {},
   "source": [
    "### <font color='saddlebrown'> Import Packages</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2437ff5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting wikipedia-api\n",
      "  Downloading Wikipedia_API-0.6.0-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: requests in /home/melak/anaconda3/lib/python3.9/site-packages (from wikipedia-api) (2.28.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/melak/anaconda3/lib/python3.9/site-packages (from requests->wikipedia-api) (2022.9.14)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/melak/anaconda3/lib/python3.9/site-packages (from requests->wikipedia-api) (1.26.11)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/melak/anaconda3/lib/python3.9/site-packages (from requests->wikipedia-api) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/melak/anaconda3/lib/python3.9/site-packages (from requests->wikipedia-api) (3.3)\n",
      "Installing collected packages: wikipedia-api\n",
      "Successfully installed wikipedia-api-0.6.0\n"
     ]
    }
   ],
   "source": [
    "!pip install wikipedia-api\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5350307",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/melak/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/melak/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "import wikipediaapi\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e78fa8",
   "metadata": {},
   "source": [
    "### <font color='saddlebrown'> Fetch from Wikipedia</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aed5d6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wikipediaapi\n",
    "import json\n",
    "\n",
    "def fetch_wikipedia_content(wiki_api, titles, size_limit_mb):\n",
    "    content_dict = {}\n",
    "    total_size_mb = 0\n",
    "\n",
    "    for title in titles:\n",
    "        page = wiki_api.page(title)\n",
    "        if not page.exists():\n",
    "            continue  # Skip non-existent pages\n",
    "        page_content = page.text\n",
    "        content_size_mb = len(page_content.encode('utf-8')) / (1024 ** 2)\n",
    "\n",
    "        if total_size_mb + content_size_mb > size_limit_mb:\n",
    "            return content_dict  # Return the current content if adding more would exceed the limit\n",
    "\n",
    "        content_dict[title] = page_content\n",
    "        total_size_mb += content_size_mb\n",
    "\n",
    "    return content_dict\n",
    "\n",
    "def write_to_json(file_name, data):\n",
    "    with open(file_name, 'w', encoding='utf-8') as json_file:\n",
    "        json.dump(data, json_file, ensure_ascii=False, indent=4)\n",
    "\n",
    "ai_ml_titles = [\n",
    "    \"Artificial Intelligence\", \"Machine Learning\", \"Deep Learning\", \"Neural Networks\",\n",
    "    \"Supervised Learning\", \"Unsupervised Learning\", \"Reinforcement Learning\",\n",
    "    \"Natural Language Processing\", \"Computer Vision\", \"Speech Recognition\",\n",
    "    \"Genetic Algorithms\", \"Support Vector Machines\", \"Decision Trees\",\n",
    "    \"Random Forests\", \"Gradient Boosting Machines\", \"Convolutional Neural Networks\",\n",
    "    \"Recurrent Neural Networks\", \"Transfer Learning\", \"Feature Engineering\",\n",
    "    \"Bias-Variance Tradeoff\", \"Dimensionality Reduction\", \"Principal Component Analysis\",\n",
    "    \"Clustering Algorithms\", \"K-Means Clustering\", \"Hierarchical Clustering\",\n",
    "    \"Deep Reinforcement Learning\", \"Generative Adversarial Networks\", \"Robotics\",\n",
    "    \"Ethics in AI\", \"Explainable AI\", \"AI in Healthcare\", \"AI in Finance\",\n",
    "    \"AI in Autonomous Vehicles\", \"AI in Gaming\", \"Data Mining\", \"Big Data Analytics\"\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "user_agent = \"MyApp/1.0 (melakemekonnen100@gmail.com)\"\n",
    "wiki_wiki = wikipediaapi.Wikipedia(language='en', extract_format=wikipediaapi.ExtractFormat.WIKI, user_agent=user_agent)\n",
    "\n",
    "ai_ml_content = fetch_wikipedia_content(wiki_wiki, ai_ml_titles, 128)\n",
    "write_to_json('ai_ml_data.json', ai_ml_content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "682dd0b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric                         | Value          \n",
      "-----------------------------------------------\n",
      "File Size                      | 0.82            MB\n",
      "Number of Pages                | 20             \n",
      "Total Word Count               | 107798         \n",
      "Distinct Articles              | 20             \n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "def load_data(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        return json.load(file)\n",
    "\n",
    "def get_file_metrics(data, file_path):\n",
    "    file_size_mb = os.path.getsize(file_path) / (1024 ** 2)\n",
    "    num_pages = len(data)\n",
    "    total_word_count = sum(len(content.split()) for content in data.values())\n",
    "    distinct_articles = set(data.keys())\n",
    "\n",
    "    return file_size_mb, num_pages, total_word_count, distinct_articles\n",
    "\n",
    "def display_metrics(file_size_mb, num_pages, total_word_count, distinct_articles):\n",
    "    # Header\n",
    "    print(\"{:<30} | {:<15}\".format(\"Metric\", \"Value\"))\n",
    "    print(\"-\" * 47)\n",
    "\n",
    "    # Metrics\n",
    "    print(\"{:<30} | {:<15.2f} MB\".format(\"File Size\", file_size_mb))\n",
    "    print(\"{:<30} | {:<15}\".format(\"Number of Pages\", num_pages))\n",
    "    print(\"{:<30} | {:<15}\".format(\"Total Word Count\", total_word_count))\n",
    "    print(\"{:<30} | {:<15}\".format(\"Distinct Articles\", len(distinct_articles)))\n",
    "\n",
    "# Main code\n",
    "json_file_path = 'ai_ml_data.json'\n",
    "data = load_data(json_file_path)\n",
    "file_size_mb, num_pages, total_word_count, distinct_articles = get_file_metrics(data, json_file_path)\n",
    "display_metrics(file_size_mb, num_pages, total_word_count, distinct_articles)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9d635586",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slice 1:\n",
      "In computer science, artificial intelligence (AI), sometimes called machine intelligence, is intelligence demonstrated by machines, in contrast to the natural intelligence displayed by humans and animals. Leading AI textbooks define the field as the study of 'intelligent agents': any device that perceives its environment and takes actions that maximize its chance of successfully achieving its goals. Colloquially, the term 'artificial intelligence' is often used to describe machines (or computers\n",
      "\n",
      "Slice 2:\n",
      "s. Colloquially, the term 'artificial intelligence' is often used to describe machines (or computers) that mimic 'cognitive' functions that humans associate with the human mind, such as 'learning' and 'problem solving'. As machines become increasingly capable, tasks considered to require 'intelligence' are often removed from the definition of AI, a phenomenon known as the AI effect. A quip in Tesler's Theorem says 'AI is whatever hasn't been done yet.' For instance, optical character recognition\n",
      "\n",
      "Slice 3:\n",
      "er's Theorem says 'AI is whatever hasn't been done yet.' For instance, optical character recognition is frequently excluded from things considered to be AI, having become a routine technology.In computer science, artificial intelligence (AI), sometimes called machine intelligence, is intelligence demonstrated by machines, in contrast to the natural intelligence displayed by humans and animals. Leading AI textbooks define the field as the study of 'intelligent agents': any device that perceives i\n",
      "\n",
      "Slice 4:\n",
      "ding AI textbooks define the field as the study of 'intelligent agents': any device that perceives its environment and takes actions that maximize its chance of successfully achieving its goals. Colloquially, the term 'artificial intelligence' is often used to describe machines (or computers) that mimic 'cognitive' functions that humans associate with the human mind, such as 'learning' and 'problem solving'. As machines become increasingly capable, tasks considered to require 'intelligence' are \n",
      "\n",
      "Slice 5:\n",
      "m solving'. As machines become increasingly capable, tasks considered to require 'intelligence' are often removed from the definition of AI, a phenomenon known as the AI effect. A quip in Tesler's Theorem says 'AI is whatever hasn't been done yet.' For instance, optical character recognition is frequently excluded from things considered to be AI, having become a routine technology.In computer science, artificial intelligence (AI), sometimes called machine intelligence, is intelligence demonstrat\n",
      "\n",
      "Slice 6:\n",
      "nce, artificial intelligence (AI), sometimes called machine intelligence, is intelligence demonstrated by machines, in contrast to the natural intelligence displayed by humans and animals. Leading AI textbooks define the field as the study of 'intelligent agents': any device that perceives its environment and takes actions that maximize its chance of successfully achieving its goals. Colloquially, the term 'artificial intelligence' is often used to describe machines (or computers) that mimic 'co\n",
      "\n",
      "Slice 7:\n",
      " the term 'artificial intelligence' is often used to describe machines (or computers) that mimic 'cognitive' functions that humans associate with the human mind, such as 'learning' and 'problem solving'. As machines become increasingly capable, tasks considered to require 'intelligence' are often removed from the definition of AI, a phenomenon known as the AI effect. A quip in Tesler's Theorem says 'AI is whatever hasn't been done yet.' For instance, optical character recognition is frequently e\n",
      "\n",
      "Slice 8:\n",
      "s 'AI is whatever hasn't been done yet.' For instance, optical character recognition is frequently excluded from things considered to be AI, having become a routine technology.In computer science, artificial intelligence (AI), sometimes called machine intelligence, is intelligence demonstrated by machines, in contrast to the natural intelligence displayed by humans and animals. Leading AI textbooks define the field as the study of 'intelligent agents': any device that perceives its environment a\n",
      "\n",
      "Slice 9:\n",
      "s define the field as the study of 'intelligent agents': any device that perceives its environment and takes actions that maximize its chance of successfully achieving its goals. Colloquially, the term 'artificial intelligence' is often used to describe machines (or computers) that mimic 'cognitive' functions that humans associate with the human mind, such as 'learning' and 'problem solving'. As machines become increasingly capable, tasks considered to require 'intelligence' are often removed fr\n",
      "\n",
      "Slice 10:\n",
      "achines become increasingly capable, tasks considered to require 'intelligence' are often removed from the definition of AI, a phenomenon known as the AI effect. A quip in Tesler's Theorem says 'AI is whatever hasn't been done yet.' For instance, optical character recognition is frequently excluded from things considered to be AI, having become a routine technology.In computer science, artificial intelligence (AI), sometimes called machine intelligence, is intelligence demonstrated by machines, \n",
      "\n",
      "Slice 11:\n",
      "intelligence (AI), sometimes called machine intelligence, is intelligence demonstrated by machines, in contrast to the natural intelligence displayed by humans and animals. Leading AI textbooks define the field as the study of 'intelligent agents': any device that perceives its environment and takes actions that maximize its chance of successfully achieving its goals. Colloquially, the term 'artificial intelligence' is often used to describe machines (or computers) that mimic 'cognitive' functio\n",
      "\n",
      "Slice 12:\n",
      "icial intelligence' is often used to describe machines (or computers) that mimic 'cognitive' functions that humans associate with the human mind, such as 'learning' and 'problem solving'. As machines become increasingly capable, tasks considered to require 'intelligence' are often removed from the definition of AI, a phenomenon known as the AI effect. A quip in Tesler's Theorem says 'AI is whatever hasn't been done yet.' For instance, optical character recognition is frequently excluded from thi\n",
      "\n",
      "Slice 13:\n",
      "r hasn't been done yet.' For instance, optical character recognition is frequently excluded from things considered to be AI, having become a routine technology.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "long_text = (\"In computer science, artificial intelligence (AI), sometimes called machine intelligence, \"\n",
    "             \"is intelligence demonstrated by machines, in contrast to the natural intelligence displayed by humans \"\n",
    "             \"and animals. Leading AI textbooks define the field as the study of 'intelligent agents': any device that \"\n",
    "             \"perceives its environment and takes actions that maximize its chance of successfully achieving its goals. \"\n",
    "             \"Colloquially, the term 'artificial intelligence' is often used to describe machines (or computers) that \"\n",
    "             \"mimic 'cognitive' functions that humans associate with the human mind, such as 'learning' and 'problem solving'. \"\n",
    "             \"As machines become increasingly capable, tasks considered to require 'intelligence' are often removed from the \"\n",
    "             \"definition of AI, a phenomenon known as the AI effect. A quip in Tesler's Theorem says 'AI is whatever hasn't \"\n",
    "             \"been done yet.' For instance, optical character recognition is frequently excluded from things considered to be AI, \"\n",
    "             \"having become a routine technology.\") * 5  \n",
    "\n",
    "#Preprocess \n",
    "def preprocess_text(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [word for word in tokens if word not in stopwords.words('english')]\n",
    "    stemmer = PorterStemmer()\n",
    "    stemmed_tokens = [stemmer.stem(word) for word in tokens]\n",
    "    return ' '.join(stemmed_tokens)\n",
    "\n",
    "def calculate_cosine_similarity(slice1, slice2):\n",
    "    vectorizer = CountVectorizer().fit([slice1, slice2])\n",
    "    vectorized_slices = vectorizer.transform([slice1, slice2])\n",
    "    similarity = cosine_similarity(vectorized_slices)[0][1]\n",
    "    return similarity\n",
    "\n",
    "def slice_input(input_text, slice_size=500, overlap=100):\n",
    "    slices = []\n",
    "    start = 0\n",
    "    end = slice_size\n",
    "\n",
    "    while start < len(input_text):\n",
    "   \n",
    "        current_slice = input_text[start:end]\n",
    "        slices.append(current_slice)\n",
    "        print(f\"Slice {len(slices)}:\\n{current_slice}\\n\")\n",
    "\n",
    "        start = end - overlap\n",
    "        end = start + slice_size\n",
    "\n",
    "    return slices\n",
    "\n",
    "sliced_demo_text = slice_input(long_text)\n",
    "#len(sliced_demo_text), sliced_demo_text[:3]  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43fe78f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
